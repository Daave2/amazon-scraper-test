name: Full INF Scrape

# ==============================================================================
# ─── PURPOSE ──────────────────────────────────────────────────────────────────
# This workflow runs a full INF analysis for ALL stores using Yesterday's data.
# It is triggered manually or can be scheduled.
# ==============================================================================

on:
  # Manual trigger
  workflow_dispatch:
    inputs:
      date_mode:
        description: 'Date range mode'
        required: false
        default: 'today'
        type: choice
        options:
          - today
          - yesterday
          - last_7_days
          - last_30_days
      top_items:
        description: 'Number of top INF items to show per store'
        required: false
        default: '5'
        type: choice
        options:
          - '5'
          - '10'
          - '25'

  # Scheduled: Optional, e.g. weekly
  # schedule:
  #   - cron: '0 8 * * 1'  # Every Monday at 8 AM

# Abort an older run if a new one starts
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.11'

jobs:
  full-inf-scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # Increased timeout for full scrape

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install Python dependencies
      run: pip install -r requirements.txt

    - name: Cache Playwright browsers
      uses: actions/cache@v4
      id: playwright-cache
      with:
        path: ~/.cache/ms-playwright
        key: ${{ runner.os }}-playwright-${{ hashFiles('requirements.txt') }}

    - name: Install Playwright browsers & deps
      run: python -m playwright install --with-deps chromium

    - name: Build runtime config from Secrets
      env:
        FORM_URL:        ${{ secrets.FORM_URL }}
        LOGIN_URL:       ${{ secrets.LOGIN_URL }}
        SECRET_KEY:      ${{ secrets.SECRET_KEY }}
        LOGIN_EMAIL:     ${{ secrets.LOGIN_EMAIL }}
        LOGIN_PASSWORD:  ${{ secrets.LOGIN_PASSWORD }}
        OTP_SECRET_KEY:  ${{ secrets.OTP_SECRET_KEY }}
        CHAT_WEBHOOK_URL: ${{ secrets.CHAT_WEBHOOK_URL }}
        APPS_SCRIPT_WEBHOOK_URL: ${{ secrets.APPS_SCRIPT_WEBHOOK_URL }}
        MORRISONS_API_KEY: ${{ secrets.MORRISONS_API_KEY }}
        MORRISONS_BEARER_TOKEN_URL: ${{ secrets.MORRISONS_BEARER_TOKEN_URL }}
      run: |
        cat > config.json <<JSON
        {
          "debug": false,
          "form_url":        "${FORM_URL}",
          "login_url":       "${LOGIN_URL}",
          "secret_key":      "${SECRET_KEY}",
          "login_email":     "${LOGIN_EMAIL}",
          "login_password":  "${LOGIN_PASSWORD}",
          "otp_secret_key":  "${OTP_SECRET_KEY}",
          "chat_webhook_url": "${CHAT_WEBHOOK_URL}",
          "apps_script_webhook_url": "${APPS_SCRIPT_WEBHOOK_URL}",
          "max_concurrency": 55,
          "initial_concurrency": 30,
          "num_form_submitters": 2,
          "page_timeout_ms": 90000,
          "element_wait_timeout_ms": 20000,
          "auto_concurrency": {
            "enabled": true,
            "min_concurrency": 1,
            "max_concurrency": 50,
            "cpu_upper_threshold": 90,
            "cpu_lower_threshold": 75,
            "mem_upper_threshold": 90,
            "check_interval_seconds": 1,
            "cooldown_seconds": 3
          },
          "use_date_range": false,
          "morrisons_api_key": "${MORRISONS_API_KEY}",
          "morrisons_bearer_token_url": "${MORRISONS_BEARER_TOKEN_URL}",
          "enrich_stock_data": true,
          "inventory_system_url": "https://amazon-product-analysis-584939250419.us-west1.run.app/assistant/{sku}?locationId={store_number}"
        }
        JSON

    - name: Download auth state from previous run
      uses: dawidd6/action-download-artifact@v6
      with:
        workflow: run-scraper.yml
        name: auth-state
        path: .
        if_no_artifact_found: warn
        search_artifacts: true

    - name: Determine date mode - use input if provided, otherwise default to 'today'
      id: date-mode
      run: |
        DATE_MODE="${{ github.event.inputs.date_mode || 'today' }}"
        echo "DATE_MODE=$DATE_MODE" >> $GITHUB_ENV
        TOP_ITEMS="${{ github.event.inputs.top_items || '5' }}"
        echo "TOP_ITEMS=$TOP_ITEMS" >> $GITHUB_ENV

    - name: Run Full INF Scrape
      env:
        PWDEBUG: 0
        GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
      run: |
        python scraper.py --date-mode "$DATE_MODE" --inf-only --top-n "$TOP_ITEMS"


    - name: Upload artifacts on failure or success
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-output-full-inf-${{ github.run_id }}
        path: |
          output/
          app.log
          state.json
        retention-days: 7

    - name: Upload auth state
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: auth-state
        path: state.json
        retention-days: 7
        overwrite: true
